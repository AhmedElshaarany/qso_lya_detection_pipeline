{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to end DLA prediction, localization, and column density measurement\n",
    "\n",
    "![title](html/sightline.png)\n",
    "\n",
    "This demo utilizes pretrained convolutional neural network classification and regression models. Predictions are executed and visualized at each step in the pipeline for DLA detection, localization, and column density measurement.\n",
    "\n",
    "This demo has no dependency other than the python files included with it, it will download the necessary FITS files, or you can specify a directory for it to load them from, you specify the plate, mjd, and fiber below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enter the plate mjd and fiber of one or more SDSS 12 fits files, the re-run all cells\n",
    "# The FITS files will be downloaded from the SDSS site and require internet access (and that the SDSS site is up)\n",
    "\n",
    "LOCAL_FITS_FILES_LOCATION = \"../../BOSS_dat_all\"\n",
    "\n",
    "PLATE_MJD_FIBER = [\n",
    "    [4637,55616,522],   # Good example (DR9:4091/20.494 +/- 0.069)\n",
    "    [5002,55710,598],   # Good example (DR9:4990/20.885 +/- 0.104)\n",
    "#     [5010,55748,888],   # No DLA example, localization off, but NO_DLA classification accurate\n",
    "    [4565,55591,868],   # Multiple DLA detection, Minor peak detection issue (DR9:5029/20.088 +/- 0.062)\n",
    "    [4091,55498,785],   # Misclassified but localization model finds DLA w/ minor issues (DR9:3856/20.685 +/- 0.113)\n",
    "#     [4568,55600,884],   # Left side issue example; bad central wavelength peaks calculations (DR9:3762/20.070 +/- 0.105)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "The following 5 components are provide for each plate-mjd-fiber:\n",
    "\n",
    "- 1) Print the central wavelength and column density measure of each DLA detected in the sightline.\n",
    "- 2) Plot of the full sightline in rest frame\n",
    "- 3) Plot of the DLA range 960A to 1216A in rest frame\n",
    "- 4) Plot of the localization confidence across the sightline (redshift matches graph 2)\n",
    "- 5) Plot of column density values measured at each point around the DLA (these values are averaged to arrive at the final printed value above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import sys\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tensorflow",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9e7264789f08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'autoreload'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mclassification_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpredictions_ann\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpredictions_ann_c1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlocalize_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpredictions_ann\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpredictions_ann_c2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_to_central_wavelength\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdensity_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpredictions_ann\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpredictions_ann_r1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\qso_project\\QSO\\public\\src\\classification_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#!/usr/bin/env python\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named tensorflow"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "import imp, json, os, urllib, numpy as np\n",
    "from classification_model import predictions_ann as predictions_ann_c1\n",
    "from localize_model import predictions_ann as predictions_ann_c2, predictions_to_central_wavelength\n",
    "from density_model import predictions_ann as predictions_ann_r1\n",
    "from data_loader import normalize, read_fits_file, DataSet, scan_flux_sample, \\\n",
    "                        scan_flux_about_central_wavelength, get_raw_data_for_classification, REST_RANGE\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "MODEL_CHECKPOINT_C1 = \"models/classification_model\"\n",
    "MODEL_CHECKPOINT_C2 = \"models/localize_model\"\n",
    "MODEL_CHECKPOINT_R1 = \"models/density_model\"\n",
    "\n",
    "\n",
    "def plot(y, x_label=\"Rest Frame\", y_label=\"Flux\", x=None, ylim=[-2,12], xlim=None, z_qso=None):\n",
    "    fig, ax = plt.subplots(figsize=(15, 3.75))\n",
    "    if x is None:\n",
    "        ax.plot(y, '-k')\n",
    "    else:\n",
    "        ax.plot(x,y,'-k')\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    plt.ylim(ylim)\n",
    "    plt.xlim(xlim)\n",
    "    \n",
    "    return fig, ax\n",
    "    \n",
    "def load_data(plate,mjd,fiber):\n",
    "    # Download the file\n",
    "    (data1, z_qso) = read_fits_file(plate, mjd, fiber, fits_base_dir=LOCAL_FITS_FILES_LOCATION, \n",
    "                                    download_if_notfound=True)\n",
    "    \n",
    "    # Classification 1 dataset\n",
    "    classification1 = get_raw_data_for_classification(data1, z_qso)\n",
    "    \n",
    "    # Classification 2 dataset\n",
    "    data = scan_flux_sample(normalize(data1, z_qso), data1['loglam'], z_qso, -1, -1, \n",
    "                            plate, mjd, fiber, exclude_positive_samples=False, \n",
    "                            kernel=400, stride=1, pos_sample_kernel_percent=0.3)\n",
    "    \n",
    "    return data1, z_qso, DataSet(classification1), DataSet(data)\n",
    "\n",
    "    \n",
    "for pmf in PLATE_MJD_FIBER:\n",
    "    # Download fits file and create a custom DataSet object\n",
    "    data1, z_qso, c1_dataset, c2_dataset = load_data(pmf[0],pmf[1],pmf[2])\n",
    "    lam = 10.0**data1['loglam']\n",
    "    lam_rest = lam/(1.0 + z_qso)\n",
    "    ix_dla_range = np.logical_and(lam_rest >= REST_RANGE[0], lam_rest <= REST_RANGE[1])\n",
    "    y_plot_range = np.mean(data1['flux'][np.logical_not(np.isnan(data1['flux']))]) + 10\n",
    "    \n",
    "    # Classification model - Load model hyperparameter file & Generate predictions\n",
    "    with open(MODEL_CHECKPOINT_C1+\"_hyperparams.json\", 'r') as fp:\n",
    "        hyperparameters_c1 = json.load(fp)\n",
    "        prediction, confidence = predictions_ann_c1(hyperparameters_c1, c1_dataset.fluxes, \n",
    "                                                    c1_dataset.labels, MODEL_CHECKPOINT_C1)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nClassified %d-%d-%d as %s with confidence of %d%% (where 50%% = guess, 100%% = confident)\"% \\\n",
    "          (pmf[0],pmf[1],pmf[2], \"HAS_DLA\" if round(prediction)==1.0 else \"NO_DLA\", int((abs(0.5-confidence)+0.5)*100)))\n",
    "    \n",
    "    # Plot full sightline\n",
    "    plot(data1['flux'], x_label=\"Full sightline in rest frame with invalid pixels removed\", \n",
    "         y_label='Flux', x=lam_rest, xlim=[REST_RANGE[0],lam_rest[-1]], ylim=[-2,y_plot_range])\n",
    "    \n",
    "    # Plot DLA range of sightline\n",
    "    (fig_sight, ax_sight) = plot(data1['flux'], x_label=\"Sightline in range %dA to 1250A, region of interest for DLA's'\"\n",
    "                                 % REST_RANGE[0], y_label='Flux', x=lam_rest,\n",
    "                                 xlim=[REST_RANGE[0],1250], ylim=[-2,y_plot_range])\n",
    "    \n",
    "    # Localization model - Load model hyperparameter file\n",
    "    with open(MODEL_CHECKPOINT_C2+\"_hyperparams.json\", 'r') as fp:\n",
    "        hyperparameters_c2 = json.load(fp)\n",
    "        loc_pred, loc_conf = predictions_ann_c2(hyperparameters_c2, c2_dataset.fluxes, \n",
    "                                                c2_dataset.labels, MODEL_CHECKPOINT_C2)\n",
    "\n",
    "    print(np.sum(ix_dla_range), np.shape(loc_conf), np.shape(loc_conf))\n",
    "    (fig, ax) = plot(loc_conf, ylim=[0,1], x=lam_rest[ix_dla_range], xlim=[REST_RANGE[0],1250], \n",
    "                     z_qso=z_qso, x_label=\"DLA Localization confidence & localization prediction(s)\")\n",
    "\n",
    "    # Identify peaks from classification-2 results\n",
    "    peaks = predictions_to_central_wavelength(loc_conf, 1, 100, 360)\n",
    "    for peak in peaks:\n",
    "        peak_lam_rest = lam_rest[ix_dla_range][peak]\n",
    "        if peak_lam_rest > 1250 or peak_lam_rest < REST_RANGE[0]:\n",
    "            print(\" > Excluded peak: %0.2f\" % peak_lam_rest)\n",
    "            continue\n",
    "\n",
    "        # Plot peak '+' markers\n",
    "        ax.plot(lam_rest[ix_dla_range][peak], loc_conf[peak], '+', mew=10, ms=20)\n",
    "\n",
    "        # Column density estimate\n",
    "        density_data = DataSet(scan_flux_about_central_wavelength(data1['flux'], data1['loglam'], z_qso, \n",
    "                                                                  peak_lam_rest*(1+z_qso), 0, 80, 0, 0, 0, 400, 0.2))\n",
    "\n",
    "        with open(MODEL_CHECKPOINT_R1+\"_hyperparams.json\", 'r') as fp:\n",
    "            hyperparameters_r1 = json.load(fp)\n",
    "            density_pred = predictions_ann_r1(hyperparameters_r1, density_data.fluxes, \n",
    "                                              density_data.labels, MODEL_CHECKPOINT_R1)\n",
    "            density_pred_np = np.array(density_pred)\n",
    "\n",
    "        mean_col_density_prediction = np.mean(density_pred_np)\n",
    "        \n",
    "        # Bar plot\n",
    "        fig_b, ax_b = plt.subplots(figsize=(15, 3.75))\n",
    "        ax_b.bar(np.arange(0,np.shape(density_pred_np)[1]), density_pred_np[0,:], 0.25)\n",
    "        ax_b.set_xlabel(\"Individual Column Density estimates for peak @ %0.0fA, +/- 0.3 of mean. \" % (peak_lam_rest) + \n",
    "                        \"Mean: %0.3f - Median: %0.3f - Stddev: %0.3f\" % (np.mean(density_pred_np), \n",
    "                        np.median(density_pred_np), np.std(density_pred_np)))\n",
    "        plt.ylim([mean_col_density_prediction-0.3,mean_col_density_prediction+0.3])\n",
    "        ax_b.plot(np.arange(0,np.shape(density_pred_np)[1]), \n",
    "                np.ones((np.shape(density_pred_np)[1],),np.float32)*mean_col_density_prediction)\n",
    "\n",
    "        # Sightline plot transparent marker boxes\n",
    "        ax_sight.fill_between(lam_rest[ix_dla_range][peak-10:peak+10], y_plot_range, -2, color='gray', lw=0, alpha=0.1)\n",
    "        ax_sight.fill_between(lam_rest[ix_dla_range][peak-30:peak+30], y_plot_range, -2, color='gray', lw=0, alpha=0.1)\n",
    "        ax_sight.fill_between(lam_rest[ix_dla_range][peak-50:peak+50], y_plot_range, -2, color='gray', lw=0, alpha=0.1)\n",
    "        ax_sight.fill_between(lam_rest[ix_dla_range][peak-70:peak+70], y_plot_range, -2, color='gray', lw=0, alpha=0.1)\n",
    "        \n",
    "        print(\" > DLA central wavelength at: %0.0fA rest / %0.0fA spectrum, has Column Density: %0.3f\"\n",
    "              %(peak_lam_rest, peak_lam_rest*(1+z_qso), mean_col_density_prediction))\n",
    "            \n",
    "    # Print URL\n",
    "    print(\" > http://dr12.sdss3.org/spectrumDetail?plateid=%d&mjd=%d&fiber=%d\"%(pmf[0],pmf[1],pmf[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
